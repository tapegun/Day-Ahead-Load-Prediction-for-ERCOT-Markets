{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Day-ahead load prediction for ERCOT (Texas) markets. \n",
    "\n",
    "In this lab, you train a neural network to predict 24-hour aggregate load from Texas for a day using history of demands. The goals for this lab are:\n",
    "1. Load the data and analyze to find patterns.\n",
    "2. Define a neural network for the regression. Try different number of layers, learning rates, linear v/s nonlinear regression, activation functions, number of epochs, etc.\n",
    "3. Explore the effects of wind energy on load prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following line suppresses certain warnings.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ERCOT data from 2015.\n",
    "\n",
    "The load data is given in the column named 'ERCOT Load, MW' in the csv file provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "year = 2015\n",
    "dfDemand = pd.read_csv(\"ERCOT_Hourly_Wind_Output_\" + str(year) + \".csv\")\n",
    "\n",
    "demands = dfDemand['ERCOT Load, MW']\n",
    "\n",
    "# Count the number of days for which we have demand data.\n",
    "numberOfDays = int(len(demands)/24)\n",
    "print(\"Hourly demand data loaded for %d days.\" % numberOfDays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand the data.\n",
    "\n",
    "It is always useful to get accustomed to the data you are trying to learn. Visualize it if you can.\n",
    "\n",
    "#### Q1. How does load vary over the year in Texas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "plt.plot([hour/24 for hour in range(numberOfDays * 24)], demands.values)\n",
    "plt.xlabel(\"Days in \" + str(year))\n",
    "plt.ylabel(\"Net demand of Texas (in MW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fact.** A significant portion of the demand is usually thermal, i.e., for air conditioners and heating systems.\n",
    "\n",
    "**Question (10 points).** From the above plot, what can you infer about the climate of Texas? What would you expect if you plotted the same in Illinois? \n",
    "\n",
    "**Your answer.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2. How does day of week affect the load profiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot the load data of the same day of the week over several weeks.\n",
    "\n",
    "dayStart = 30\n",
    "numberOfWeeks = 4\n",
    "\n",
    "DayOfWeek = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "print(\"The first day in the first plot is Jan 31, \" + str(year) + \".\")\n",
    "print(\"Day 1\", \"was a\", DayOfWeek[datetime.date(year, 1, 31).weekday()] + \".\")\n",
    "\n",
    "fig, axs = plt.subplots(7, 1, sharex=True, figsize=(5,10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for dayInFirstWeek in range(7):\n",
    "    for week in range(numberOfWeeks):\n",
    "\n",
    "        axs[dayInFirstWeek].plot(range(24), dfDemand.loc[(dayStart + 7 * week + dayInFirstWeek) * 24: \n",
    "                                                         (dayStart + 7 * week + dayInFirstWeek + 1) * 24 - 1, \n",
    "                                                         'ERCOT Load, MW'].values.flatten())\n",
    "    axs[dayInFirstWeek].set_ylim(bottom=20000, top=60000)\n",
    "    axs[dayInFirstWeek].set_title(\"Day \" + str(dayInFirstWeek + 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question (15 points).** Can you find any discernible change in the load profiles of different days of the week? Redo the above exercise for the months of August and September. Make 'Day 1' correspond to August 15th. What do you observe differently? \n",
    "\n",
    "\n",
    "**Your answer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Modify the following code\n",
    "\n",
    "# Plot the load data of the same day of the week over several weeks.\n",
    "\n",
    "dayStart = 30\n",
    "numberOfWeeks = 4\n",
    "\n",
    "DayOfWeek = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\n",
    "print(\"The first day in the first plot is August 15, \" + str(year) + \".\")\n",
    "print(\"Day 1\", \" was a \", DayOfWeek[datetime.date(year, 8, 15).weekday()] + \".\")\n",
    "\n",
    "fig, axs = plt.subplots(7, 1, sharex=True, figsize=(5,10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for dayInFirstWeek in range(7):\n",
    "    for week in range(numberOfWeeks):\n",
    "\n",
    "        axs[dayInFirstWeek].plot(range(24), dfDemand.loc[(dayStart + 7 * week + dayInFirstWeek) * 24: \n",
    "                                                         (dayStart + 7 * week + dayInFirstWeek + 1) * 24 - 1, \n",
    "                                                         'ERCOT Load, MW'].values.flatten())\n",
    "    axs[dayInFirstWeek].set_ylim(bottom=20000, top=75000)\n",
    "    axs[dayInFirstWeek].set_title(\"Day \" + str(dayInFirstWeek + 1))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the demand prediction module.\n",
    "\n",
    "Use past demand profiles to predict demands a day in advance. We draw two conclusions from the above analysis:\n",
    "1. Demand profiles have seasonal effects. Therefore, data from the past few days will help in predicting the demands tomorrow.\n",
    "2. Demand profiles have weekly dependencies. Therefore, data from the same days but a week or two before can be useful in load prediction.\n",
    "\n",
    "How much past data you want to train over depends on two considerations:\n",
    "1. Which data in the past is useful in prediction?\n",
    "2. How complex you want your training process to be? The more features of past data you want to train on, the more complex your neural network should be, and it will require more time to train it.\n",
    "\n",
    "To strike a balance, use the demand profile from $d-7, d-2, d-1$ to predict the load profile of day $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "daysToTrainOn = [-7, -2, -1]\n",
    "rangeOfDays = range(-np.min(daysToTrainOn), numberOfDays)\n",
    "\n",
    "X = [np.concatenate([dfDemand.loc[(day + h) * 24: (day + h + 1) * 24 -1, 'ERCOT Load, MW'].values.flatten()\n",
    "     for h in daysToTrainOn]) for day in rangeOfDays]\n",
    "Y = [dfDemand.loc[day * 24: (day + 1) * 24 - 1, 'ERCOT Load, MW'].values.flatten() for day in rangeOfDays]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you perform regression, it is often desirable to scale the inputs so that it has zero mean and unit variance. Other types of scaling are possible. Here, we cheat a little and scale both the training and test data together. Ideally, they should be scaled separately.\n",
    "\n",
    "Split the data into two sets: training set and testing set. Train the neural network on the training set, and test how well it performs on the testing set. You should typically never sample from the training set to test your algorithms. The learnt model for prediction should work well on data that the algorithm has never encountered before.\n",
    "\n",
    "The function 'train_test_split' helps you to split the data into two parts, where 'test_size'\n",
    "indicates the fraction of the data you want to test on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "trainX = trainX.astype(np.float32)\n",
    "testX = testX.astype(np.float32)\n",
    "trainY = np.array(trainY)\n",
    "testY = np.array(testY)\n",
    "\n",
    "print(\"Scaled and split the data into two parts:\")\n",
    "\n",
    "nTrain = np.shape(trainX)[0]\n",
    "nTest = np.shape(testX)[0]\n",
    "\n",
    "print(\"Neural network will train on data from %d days, and test on %d days.\" % (nTrain, nTest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the neural network (NN) for demand prediction with only one hidden layer.\n",
    "\n",
    "**Question (25 points). Insert code to design the NN and its optimizer (use the relu function)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nHidden = 150\n",
    "\n",
    "# Store the dimension of each row of 'X' in 'nDimX' and that of 'Y' in 'nDimY' .\n",
    "nDimX = np.shape(trainX)[1]\n",
    "nDimY = np.shape(trainY)[1]\n",
    "\n",
    "# Construct the neural network using relu\n",
    "inputs = #insert code\n",
    "nn_layer = #insert code\n",
    "outputs = #insert code\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Define the loss function (MSE) and the optimizer (AdagradOptimizer).\n",
    "\n",
    "# insert code\n",
    "model.compile(\n",
    "    optimizer= #insert code ,\n",
    "    loss= #insert code \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train the neural network via Keras.\n",
    "\n",
    "Create the training module for the NN. \n",
    "\n",
    "Keras is a user-friendly framework to define, train and test neural networks. Check their page out for more details. https://keras.io/ \n",
    "\n",
    "Feed the training data in batches of size 'batchSize'.Usually, going through the training data once does not train your NN. You train over the same data multiple times. More precisely, train it 'nEpochs' times. It is similar to the idea that you never learn a material by reading through it once!\n",
    "\n",
    "**Question (20 points). Insert code to define the training module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "batchSize = #\n",
    "nEpochs = #\n",
    "\n",
    "# Train the model\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "\n",
    "history = model.fit(\n",
    "    # insert code\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us visualize the results.\n",
    "\n",
    "**Question (5 points). Usine the NN to predict on test data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Output the accuracy of the regressor on the test data.\n",
    "\n",
    "predictedY = # insert code\n",
    "\n",
    "# Plot the predicted load and compare against the actual load from the test data.\n",
    "assert(nTest >= 16)\n",
    "days = random.sample(range(nTest), 16)\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(10,10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "\n",
    "for dd, day in enumerate(days):\n",
    "    testYDay = testY[day]\n",
    "    predictedYDay = predictedY[day]\n",
    "\n",
    "    l1 = axs[dd].plot(range(1, 25), testYDay, label='Measured')\n",
    "    l2 = axs[dd].plot(range(1, 25), predictedYDay, label='Predicted')\n",
    "    \n",
    "    axs[dd].set_ylim(bottom=0, top=75000)\n",
    "    axs[dd].legend()\n",
    "\n",
    "fig.text(0.5, 0.07, 'Time of day (in hour)', ha='center')\n",
    "fig.text(0.04, 0.5, 'Demand in Texas (in MW)', va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question (10 points).** Explore how the number of epochs affects the accuracy and speed of training. Start with 10 epochs, and increase it to 100, 1000, 5000, 10000, and maybe more (do not exceed 20000 unless you have a powerful computer, you are only required to do up to 10000 for this lab). Make comments based on your observations. As an engineer, what is your favorite number of epochs, and why? \n",
    "\n",
    "**Your answer.**\n",
    "\n",
    "**Question (15 points).** Fix the number of epochs to your favorite one. Then, add another layer to the network. Discuss what your observe in terms of speed and accuracy. \n",
    "\n",
    "**Your answer (comments here, code below). Your code should show the results for the case with an additional hidden layer. Go back to the codes above for the 1 layer case and run it again for the same number of epochs/neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The effect of wind energy (bonus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#Let's check the raw data \n",
    "dfDemand = pd.read_csv(\"ERCOT_Hourly_Wind_Output_\" + str(year) + \".csv\")\n",
    "dfDemand[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in addition to the load data, we have some wind data! \n",
    "\n",
    "**Question (20 points).** Subtract the wind data from the load, and redo the above experiment and observe how does wind energy affect the forecasting process. How does the accuracy change? Why?\n",
    "\n",
    "**Your answer (comments here, code below).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
